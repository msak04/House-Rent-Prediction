{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c0c8fe6",
   "metadata": {
    "id": "1c0c8fe6"
   },
   "source": [
    "# Predict the Rent of House in Dhaka City by Applying Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7084869a",
   "metadata": {
    "id": "7084869a"
   },
   "source": [
    "#### Contributor\n",
    "- Md. Saif Ahammod Khan\n",
    "- Rasheeq Ishmam\n",
    "- S. M. Sajid Hasan Shanta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e7e1c",
   "metadata": {
    "id": "0c3e7e1c"
   },
   "source": [
    "### Import liberary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1bb083a",
   "metadata": {
    "id": "c1bb083a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38065d1",
   "metadata": {
    "id": "b38065d1"
   },
   "source": [
    "### 1. Data Set \n",
    "We have collected two dataset from Bproperties\n",
    "1. In BpropertyManualData.csv dataset we collected manually nearby educational istitute,Medical Service, Park and Resturent Information.\n",
    "2. In BpropertyWebScrapping.csv We collected akk the house location in dhaka city\n",
    "\n",
    "After Collecting all these two dataset we marged them and made a one singel dataset named \"Primarydata\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3ad123",
   "metadata": {
    "id": "2d3ad123"
   },
   "source": [
    "#### Loading Manual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c8bfe19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "2c8bfe19",
    "outputId": "106ff819-2129-4020-c1cf-100b3a7ff5e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(896, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adress</th>\n",
       "      <th>Educational Institute</th>\n",
       "      <th>Restaurants</th>\n",
       "      <th>Medical Service</th>\n",
       "      <th>Parks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st Colony, Mirpur, Dhaka</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22 Bari, West Kazipara, Mirpur, Dhaka</td>\n",
       "      <td>47.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd Colony, Mirpur, Dhaka</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2nd Lane, Gopibag, Motijheel, Dhaka</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd Colony, Mirpur, Dhaka</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Adress  Educational Institute  Restaurants  \\\n",
       "0              1st Colony, Mirpur, Dhaka                   28.0         12.0   \n",
       "1  22 Bari, West Kazipara, Mirpur, Dhaka                   47.0         50.0   \n",
       "2              2nd Colony, Mirpur, Dhaka                   15.0         24.0   \n",
       "3    2nd Lane, Gopibag, Motijheel, Dhaka                    9.0         15.0   \n",
       "4              3rd Colony, Mirpur, Dhaka                   24.0         29.0   \n",
       "\n",
       "   Medical Service  Parks  \n",
       "0             24.0   16.0  \n",
       "1              6.0   18.0  \n",
       "2              2.0   13.0  \n",
       "3              1.0   17.0  \n",
       "4              5.0   12.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Manual_data = pd.read_csv('BpropertyManualData.csv') # raw_data is the panda's dataframe\n",
    "\n",
    "# print the shape\n",
    "print(Manual_data.shape)\n",
    "\n",
    "#runs the first 5 rows\n",
    "Manual_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc1ab30",
   "metadata": {
    "id": "6bc1ab30"
   },
   "source": [
    "#### Loading Web Scrapping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "542eeebb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "id": "542eeebb",
    "outputId": "dfee5887-15e9-42ee-c942-fc4740fe4617"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/BpropertyWebScrapping (1).csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-471bd4533719>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mWebscrapped_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/BpropertyWebScrapping (1).csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# raw_data is the panda's dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# print the shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWebscrapped_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/BpropertyWebScrapping (1).csv'"
     ]
    }
   ],
   "source": [
    "Webscrapped_data = pd.read_csv('/content/BpropertyWebScrapping (1).csv') # raw_data is the panda's dataframe\n",
    "\n",
    "# print the shape\n",
    "print(Webscrappeddata.shape)\n",
    "\n",
    "#runs the first 5 rows\n",
    "Webscrappeddata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5fd09e",
   "metadata": {
    "id": "0d5fd09e"
   },
   "source": [
    "#### Merge Both Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894bfa60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "894bfa60",
    "outputId": "3722f9bc-4aad-4745-ba44-4b245ed62cc0"
   },
   "outputs": [],
   "source": [
    "\n",
    "Primarydata = pd.merge(Webscrapped_data,Manual_data)\n",
    "print(Primarydata.shape)\n",
    "Primarydata.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc63734",
   "metadata": {
    "id": "3cc63734"
   },
   "source": [
    "\"Primarydata\" Now our primary dataset is ready now it is time for some preprocessing and drop all the unnecessary data like image link, large catagorical details etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6598cb",
   "metadata": {
    "id": "6d6598cb"
   },
   "source": [
    "### 2. Preprocessing\n",
    "Here we have droped the following unnecessary features and we have sorted the address a little bit.\n",
    "\n",
    "- Brief \t\n",
    "- Link\n",
    "- Details\n",
    "- Image Link\n",
    "- Image Link 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35be6ac",
   "metadata": {
    "id": "e35be6ac"
   },
   "source": [
    "#### Droping The Unnecessary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a01372a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a01372a",
    "outputId": "995e782b-95dc-4f20-cb6b-2060e76bc53d"
   },
   "outputs": [],
   "source": [
    "Primarydata=Primarydata.drop(labels=['Brief','Link','Details','Image Link','Image Link 2'], axis=1)\n",
    "Primarydata.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2844d7",
   "metadata": {
    "id": "ab2844d7"
   },
   "source": [
    "#### Making the adress more simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722c3530",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "722c3530",
    "outputId": "62ae2f7f-53d0-44a5-e939-c90dfd48a037"
   },
   "outputs": [],
   "source": [
    "list_add = []\n",
    "for i in range(0,38189):\n",
    "    list01 = list(Primarydata['Adress'][i].split(\", \"))\n",
    "    list_add.append(list01)\n",
    "\n",
    "l_main = []\n",
    "for i in list_add:\n",
    "     l_main.append(i[len(i)-2])\n",
    "Primarydata['Adress'] = l_main\n",
    "Primarydata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f47211c",
   "metadata": {
    "id": "7f47211c"
   },
   "source": [
    "Preprocing of data is complete. Now it is time for Encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e78bf9",
   "metadata": {
    "id": "12e78bf9"
   },
   "source": [
    "### 3. Data Encode\n",
    "\n",
    "- We have converted all the catagorical value from the dataframe into numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2812b947",
   "metadata": {
    "id": "2812b947"
   },
   "outputs": [],
   "source": [
    "EncodedData=Primarydata.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc7bc0a",
   "metadata": {
    "id": "dbc7bc0a"
   },
   "source": [
    "#### In the dataframe only Type and address are catagorical. We are converting them into numerical value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8e9f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "13c8e9f5",
    "outputId": "b0b9edf5-8811-48cf-9b51-7314dab6f4bc"
   },
   "outputs": [],
   "source": [
    "EncodedData['Type']=pd.factorize(EncodedData['Type'])[0]\n",
    "EncodedData['Adress']=pd.factorize(EncodedData['Adress'])[0]\n",
    "EncodedData.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a01f6d5",
   "metadata": {
    "id": "0a01f6d5"
   },
   "source": [
    "Encoding of data is complete. Now it is time for Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fba837",
   "metadata": {
    "id": "a7fba837"
   },
   "source": [
    "### 4. Exploratory Data\n",
    "\n",
    "Here we will explore all the features by using the following chart. At first we will visualize individual features and later on on we will visualize all of them together\n",
    "We will use following chart to visualize all the features\n",
    "\n",
    "1. Countplot\n",
    "2. Boxplot\n",
    "3. Distribution plot\n",
    "4. Regplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a5e42",
   "metadata": {
    "id": "eb7a5e42"
   },
   "source": [
    "#### Using Countplot to visualize individual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab97fbfa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "ab97fbfa",
    "outputId": "3cd59ed7-353b-4b09-9d39-a9cf981101b4"
   },
   "outputs": [],
   "source": [
    "#Count of Type of house\n",
    "ax = plt.figure(figsize = (5,3))\n",
    "sns.countplot(x ='Type', data = EncodedData)\n",
    "plt.title(\"Type of houses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d340d23",
   "metadata": {
    "id": "3d340d23"
   },
   "source": [
    "Majority Houses are Apartment Type others are almost ignorable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fad8c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "20fad8c3",
    "outputId": "5a634c9f-fe0a-42a4-fda6-d83e95165b1b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Count Number of Bedrooms\n",
    "ax = plt.figure(figsize = (5,3))\n",
    "sns.countplot(x ='Beds', data = EncodedData)\n",
    "plt.title(\"Number of Bedrooms\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f992e39",
   "metadata": {
    "id": "4f992e39"
   },
   "source": [
    "Majority Houses have 2 and 3 bedrooms only few have 1 and 4 bedrooms and 5 bedrooms is rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b91293a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "0b91293a",
    "outputId": "2cab8e94-3df2-47ba-89ea-e0481d18022c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Count Number of Bathrooms\n",
    "ax = plt.figure(figsize = (5,3))\n",
    "sns.countplot(x ='Bath', data = EncodedData)\n",
    "plt.title(\"Number of Bathrooms\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae7dd0c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "bae7dd0c",
    "outputId": "ceccc9b0-6725-4c3d-ef67-eefffca1633d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Count Number of Educational Institute\n",
    "ax = plt.figure(figsize = (30,5))\n",
    "sns.countplot(x ='Educational Institute', data = EncodedData)\n",
    "plt.title(\"Number of Educational Institute\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0e3eb6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "id": "4a0e3eb6",
    "outputId": "e5d016df-b767-447a-dccc-0bb43007c62d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Count Number of Parks\n",
    "ax = plt.figure(figsize = (30,5))\n",
    "sns.countplot(x ='Parks', data = EncodedData)\n",
    "plt.title(\"Number of Parks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4138af11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "id": "4138af11",
    "outputId": "ef5bd4e9-9921-4f4f-e8b6-c0a5fb575af8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Count Number of Restaurants\n",
    "ax = plt.figure(figsize = (30,5))\n",
    "sns.countplot(x ='Restaurants', data = EncodedData)\n",
    "plt.title(\"Number of Restaurants\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db29139c",
   "metadata": {
    "id": "db29139c"
   },
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30c130",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "id": "4e30c130",
    "outputId": "af3db56f-9bb4-4260-80c0-0b44dd65b3c3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Count Number of Medical Service\n",
    "ax = plt.figure(figsize = (30,5))\n",
    "sns.countplot(x ='Medical Service', data = EncodedData)\n",
    "plt.title(\"Number of Medical Service\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6c4973",
   "metadata": {
    "id": "2c6c4973"
   },
   "source": [
    "#### Using Boxplot to visualize all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc6f025",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "9bc6f025",
    "outputId": "8081b263-b412-477a-f32c-db4fff99865b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=5, nrows=2, figsize=(20, 10))\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for k,v in EncodedData.items():\n",
    "    sns.boxplot(y=k, data=EncodedData, ax=axs[index])\n",
    "    index += 1\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cbe70f",
   "metadata": {
    "id": "80cbe70f"
   },
   "source": [
    "#### Using Subplot to visualize all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7847c694",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7847c694",
    "outputId": "3350cae2-8e87-4475-fe8c-2f89799f2e3a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=5, nrows=2, figsize=(20, 10))\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for k,v in EncodedData.items():\n",
    "    sns.distplot(v, ax=axs[index])\n",
    "    index += 1\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe40ed96",
   "metadata": {
    "id": "fe40ed96"
   },
   "source": [
    "#### Price density visualizing using Distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55188b4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "id": "55188b4f",
    "outputId": "c2fba7cc-903c-4060-f8f5-e2afe418ecba",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4),dpi=150)\n",
    "sns.distplot(EncodedData['Price'],hist_kws=dict(edgecolor='red' ,linewidth=3),color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e007b1",
   "metadata": {
    "id": "50e007b1"
   },
   "source": [
    "#### Visualize all the features against price using Reg plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8332b30d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "8332b30d",
    "outputId": "8cbfb649-5506-4167-9c0d-54645955c1c9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Let's scale the columns before plotting them against Price\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "column_sels = ['Type', 'Beds', 'Bath', 'Size', 'Educational Institute','Restaurants', 'Medical Service', 'Parks']\n",
    "x = EncodedData.loc[:,column_sels]\n",
    "y = EncodedData['Price']\n",
    "x = pd.DataFrame(data=min_max_scaler.fit_transform(x), columns=column_sels)\n",
    "fig, axs = plt.subplots(ncols=4, nrows=3, figsize=(20, 10))\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for i, k in enumerate(column_sels):\n",
    "    sns.regplot(y=y, x=x[k], ax=axs[i])\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f8cc59",
   "metadata": {
    "id": "99f8cc59"
   },
   "source": [
    "### 5. Data Cleaning\n",
    "\n",
    "- At first we cheacked if there are any missing value\n",
    "- We counted all the missing values\n",
    "- We replaced all the missing value with interpolation to find missing value with help of its neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc0d28",
   "metadata": {
    "id": "a0fc0d28"
   },
   "outputs": [],
   "source": [
    "CleanedData=EncodedData.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36c3770",
   "metadata": {
    "id": "e36c3770"
   },
   "source": [
    "#### Checking if there is any null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e404d77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e404d77",
    "outputId": "09adcbeb-afe2-43dd-8560-75295dae40a9"
   },
   "outputs": [],
   "source": [
    "CleanedData.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b2c87d",
   "metadata": {
    "id": "13b2c87d"
   },
   "source": [
    "#### Counting all the null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae40899d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae40899d",
    "outputId": "4da83448-45ac-4796-9e52-7a9b7278ec91"
   },
   "outputs": [],
   "source": [
    "CleanedData.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e92145",
   "metadata": {
    "id": "93e92145"
   },
   "source": [
    "#### Using interpolation to find missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88fa62",
   "metadata": {
    "id": "bf88fa62"
   },
   "outputs": [],
   "source": [
    "CleanedData=EncodedData.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d0958",
   "metadata": {
    "id": "a99d0958"
   },
   "source": [
    "#### Checking if there are any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa55007c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa55007c",
    "outputId": "edddc93a-9253-402d-d9ad-bbfd9d3db899"
   },
   "outputs": [],
   "source": [
    "CleanedData.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57321bde",
   "metadata": {
    "id": "57321bde"
   },
   "source": [
    "### 6. Features Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b5216b",
   "metadata": {
    "id": "f9b5216b"
   },
   "source": [
    "#### Heat map where it is showing all the corelation between each and every features (Target value is also included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda9541",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "id": "6bda9541",
    "outputId": "1d4de83a-9219-4868-f31c-c0ce2999e619",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,12))\n",
    "sns.heatmap(CleanedData.corr(),annot=True,cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4cac55",
   "metadata": {
    "id": "ed4cac55"
   },
   "source": [
    "#### Visualizing the co relation with price for selecting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d7b16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 736
    },
    "id": "343d7b16",
    "outputId": "fa9e97dc-d9ba-4ec7-b0ce-099b4804ad85",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CleanedData.corrwith(CleanedData.Price).plot.bar(figsize=(20,10),title=\"Correlation with Price \",fontsize=15,rot=45,grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd8a13a",
   "metadata": {
    "id": "9bd8a13a"
   },
   "source": [
    "#### Dropping all the data which has less corelation on the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344926c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "344926c4",
    "outputId": "2cf937bf-cd49-4a29-8ddf-91f5ca298a98"
   },
   "outputs": [],
   "source": [
    "SelectedFeaturedData=CleanedData.drop(labels=['Adress','Educational Institute','Restaurants'], axis=1)\n",
    "SelectedFeaturedData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf4bed",
   "metadata": {
    "id": "3fdf4bed"
   },
   "source": [
    "### 7. Data Split\n",
    "- At first we have stored all the features in X and the target value in Y\n",
    "- We have selected 30% of data as a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04547590",
   "metadata": {
    "id": "04547590"
   },
   "source": [
    "#### Spliting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23a55b",
   "metadata": {
    "id": "7b23a55b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = SelectedFeaturedData.drop(['Price'], axis=1)\n",
    "y = SelectedFeaturedData.Price\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c00325",
   "metadata": {
    "id": "d7c00325"
   },
   "source": [
    "#### Counting all the test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7597c70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7597c70",
    "outputId": "f98b613a-086e-4224-984f-0c6218113f31",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Shape of X_train: \",X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_train: \",y_train.shape)\n",
    "print(\"Shape of y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ca6a9a",
   "metadata": {
    "id": "55ca6a9a"
   },
   "source": [
    "### 8. Data Scaling\n",
    "We scaled the data into two category\n",
    "- Converted into norm\n",
    "- Standardizied the values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4201d81",
   "metadata": {
    "id": "d4201d81"
   },
   "source": [
    "#### Converting all the features into norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d1fab0",
   "metadata": {
    "id": "22d1fab0"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# transform training data\n",
    "X_train_norm = norm.transform(X_train)\n",
    "\n",
    "# transform testing dataabs\n",
    "X_test_norm = norm.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a760db2d",
   "metadata": {
    "id": "a760db2d"
   },
   "source": [
    "#### Standardization of all values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a17c962",
   "metadata": {
    "id": "3a17c962"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# copy of datasets\n",
    "X_train_stand = X_train.copy()\n",
    "X_test_stand = X_test.copy()\n",
    "\n",
    "# numerical features\n",
    "num_cols = ['Type', 'Beds', 'Bath', 'Size', 'Medical Service', 'Parks']\n",
    "\n",
    "# apply standardization on numerical features\n",
    "for i in num_cols:\n",
    "    \n",
    "    # fit on training data column\n",
    "    scale = StandardScaler().fit(X_train_stand[[i]])\n",
    "    \n",
    "    # transform the training data column\n",
    "    X_train_stand[i] = scale.transform(X_train_stand[[i]])\n",
    "    \n",
    "    # transform the testing data column\n",
    "    X_test_stand[i] = scale.transform(X_test_stand[[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b948c",
   "metadata": {
    "id": "689b948c"
   },
   "source": [
    "### 9. Train Model \n",
    "We have used  six regression algorithms those are.\n",
    "- Linear Regression\n",
    "- Ridge regression\n",
    "- LASSO Regression\n",
    "- Decision Tree\n",
    "- Random Forest Regressor\n",
    "- Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c68bcba",
   "metadata": {
    "id": "6c68bcba"
   },
   "source": [
    "#### 9.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f857fba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "0f857fba",
    "outputId": "26c51542-e8a7-44a4-dea8-9ba99e8e365c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score,mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression #LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
    "regressor_linear = LinearRegression()\n",
    "\n",
    "rmseL = []\n",
    "mseL=[]\n",
    "maeL=[]\n",
    "r2L=[]\n",
    "cv_linear=[]\n",
    "# raw, normalized and standardized training and testing data\n",
    "trainX = [X_train, X_train_norm, X_train_stand]\n",
    "testX = [X_test, X_test_norm, X_test_stand]\n",
    "\n",
    "# model fitting and measuring RMSE\n",
    "for i in range(len(trainX)):\n",
    "  regressor_linear.fit(trainX[i],y_train)\n",
    "  pred = regressor_linear.predict(testX[i])\n",
    "  rmseL.append(np.sqrt(mean_squared_error(y_test,pred)))\n",
    "  mseL.append(mean_squared_error(y_test,pred))\n",
    "  maeL.append(mean_absolute_error(y_test,pred))\n",
    "  r2L.append(r2_score(y_test,pred))\n",
    "  cv_linear.append(cross_val_score(estimator = regressor_linear, X = trainX[i], y = y_train, cv = 10))\n",
    "# visualizing the result\n",
    "df_Linear = pd.DataFrame({'Root Mean Square Error(RMSE-Linear)':rmseL},index=['Original','Normalized','Standardized'])\n",
    "df_Linear1 = pd.DataFrame({'Mean Squared Error (MSE-Linear)':mseL},index=['Original','Normalized','Standardized'])\n",
    "df_Linear2 = pd.DataFrame({'Mean Absolute Error (MAE-Linear)':maeL},index=['Original','Normalized','Standardized'])\n",
    "df_Linear3 = pd.DataFrame({'R2 Score-Linear':r2L},index=['Original','Normalized','Standardized'])\n",
    "df_Linea4=pd.DataFrame({'Cross Validation-xgboost':cv_linear},index=['Original','Normalized','Standardized'])\n",
    "\n",
    "result = pd.concat([df_Linear, df_Linear1,df_Linear2,df_Linear3,df_Linea4], axis=1, join='inner')\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea8df9",
   "metadata": {
    "id": "5dea8df9"
   },
   "source": [
    "#### 9.2 Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d42eb2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "f8d42eb2",
    "outputId": "987680be-65c3-4235-de77-c377d796d8c5"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', Ridge(alpha=3.8, fit_intercept=True))\n",
    "]\n",
    "\n",
    "ridge_pipe = Pipeline(steps)\n",
    "\n",
    "rmse_ridge = []\n",
    "mse_ridge=[]\n",
    "mae_ridge=[]\n",
    "r2_ridge=[]\n",
    "cv_ridge=[]\n",
    "\n",
    "\n",
    "# model fitting and measuring RMSE\n",
    "for i in range(len(trainX)):\n",
    "  ridge_pipe.fit(trainX[i],y_train)\n",
    "  pred = ridge_pipe.predict(testX[i])\n",
    "  rmse_ridge.append(np.sqrt(mean_squared_error(y_test,pred)))\n",
    "  mse_ridge.append(mean_squared_error(y_test,pred))\n",
    "  mae_ridge.append(mean_absolute_error(y_test,pred))\n",
    "  r2_ridge.append(r2_score(y_test,pred))\n",
    "  cv_ridge.append(cross_val_score(estimator = ridge_pipe, X = trainX[i], y = y_train.ravel(), cv = 10))\n",
    "  \n",
    "# visualizing the result\n",
    "df_ridge = pd.DataFrame({'Root Mean Square Error(RMSE-Ridge)':rmse_ridge},index=['Original','Normalized','Standardized'])\n",
    "df_ridge1 = pd.DataFrame({'Mean Squared Error (MSE-Ridge)':mse_ridge},index=['Original','Normalized','Standardized'])\n",
    "df_ridge2 = pd.DataFrame({'Mean Absolute Error (MAE-Ridge)':mae_ridge},index=['Original','Normalized','Standardized'])\n",
    "df_ridge3 = pd.DataFrame({'R2 Score-Ridge':r2_ridge},index=['Original','Normalized','Standardized'])\n",
    "df_ridge4=pd.DataFrame({'Cross Validation-xgboost':cv_linear},index=['Original','Normalized','Standardized'])\n",
    "result1 = pd.concat([df_ridge, df_ridge1,df_ridge2,df_ridge3,df_ridge4], axis=1, join='inner')\n",
    "\n",
    "result1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3f3c33",
   "metadata": {
    "id": "8f3f3c33"
   },
   "source": [
    "#### 9.3 LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03826f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d03826f9",
    "outputId": "1aa9012a-03ee-4f39-a1d2-979505936bf8"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', Lasso(alpha=0.012, fit_intercept=True, max_iter=3000))\n",
    "]\n",
    "\n",
    "lasso_pipe = Pipeline(steps)\n",
    "\n",
    "rmse_lesso = []\n",
    "mse_lesso=[]\n",
    "mae_lesso=[]\n",
    "r2_lesso=[]\n",
    "cv_lasso=[]\n",
    "\n",
    "# model fitting and measuring RMSE\n",
    "for i in range(len(trainX)):\n",
    "  lasso_pipe.fit(trainX[i],y_train)\n",
    "  pred = lasso_pipe.predict(testX[i])\n",
    "  rmse_lesso.append(np.sqrt(mean_squared_error(y_test,pred)))\n",
    "  mse_lesso.append(mean_squared_error(y_test,pred))\n",
    "  mae_lesso.append(mean_absolute_error(y_test,pred))\n",
    "  r2_lesso.append(r2_score(y_test,pred))\n",
    "  cv_lasso.append(cross_val_score(estimator = lasso_pipe, X = trainX[i], y = y_train, cv = 10))\n",
    "  \n",
    "# visualizing the result\n",
    "df_lesso = pd.DataFrame({'Root Mean Square Error(RMSE-Lasso)':rmse_lesso},index=['Original','Normalized','Standardized'])\n",
    "df_lesso1 = pd.DataFrame({'Mean Squared Error (MSE-Lasso)':mse_lesso},index=['Original','Normalized','Standardized'])\n",
    "df_lesso2 = pd.DataFrame({'Mean Absolute Error (MAE-Lasso)':mae_lesso},index=['Original','Normalized','Standardized'])\n",
    "df_lesso3 = pd.DataFrame({'R2 Score-Lasso':r2_lesso},index=['Original','Normalized','Standardized'])\n",
    "df_lesso4 =pd.DataFrame({'Cross Validation-Lasso':cv_lasso},index=['Original','Normalized','Standardized'])\n",
    "result2 = pd.concat([df_lesso, df_lesso1,df_lesso2,df_lesso3,df_lesso4], axis=1, join='inner')\n",
    "\n",
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331da5c3",
   "metadata": {
    "id": "331da5c3"
   },
   "source": [
    "#### 9.4 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29501fd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "29501fd1",
    "outputId": "1b5d4fa2-da15-4d35-b4c3-e28989e8b65d"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor_dt = DecisionTreeRegressor(random_state = 0)\n",
    "\n",
    "rmseD = []\n",
    "mseD=[]\n",
    "maeD=[]\n",
    "r2D=[]\n",
    "cv_dt=[]\n",
    "\n",
    "# model fitting and measuring RMSE\n",
    "for i in range(len(trainX)):\n",
    "  regressor_dt.fit(trainX[i],y_train)\n",
    "    # predict\n",
    "  pred = regressor_dt.predict(testX[i])\n",
    "    # RMSE\n",
    "  rmseD.append(np.sqrt(mean_squared_error(y_test,pred)))\n",
    "  mseD.append(mean_squared_error(y_test,pred))\n",
    "  maeD.append(mean_absolute_error(y_test,pred))\n",
    "  r2D.append(r2_score(y_test,pred))\n",
    "  cv_dt.append(cross_val_score(estimator = regressor_dt, X = trainX[i], y = y_train, cv = 10))\n",
    "\n",
    "# visualizing the result    \n",
    "df_dt = pd.DataFrame({'Root Mean Square Error(RMSE-DecisionTree)':rmseD},index=['Original','Normalized','Standardized'])\n",
    "df_dt1 = pd.DataFrame({'Mean Squared Error (MSE-DecisionTree)':mseD},index=['Original','Normalized','Standardized'])\n",
    "df_dt2 = pd.DataFrame({'Mean Absolute Error (MAE-DecisionTree)':maeD},index=['Original','Normalized','Standardized'])\n",
    "df_dt3=pd.DataFrame({'R2 Score-DecisionTree':r2D},index=['Original','Normalized','Standardized'])\n",
    "df_dt4 =pd.DataFrame({'Cross Validation-DecisionTree':cv_dt},index=['Original','Normalized','Standardized'])\n",
    "result3 = pd.concat([df_dt, df_dt1,df_dt2,df_dt3,df_dt4], axis=1, join='inner')\n",
    "result3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f1e6ac",
   "metadata": {
    "id": "42f1e6ac"
   },
   "source": [
    "#### 9.5 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82de448",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "f82de448",
    "outputId": "5da42186-f387-4da7-8f78-5625a02d7c2b"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor_rf = RandomForestRegressor(n_estimators = 500, random_state = 0)\n",
    "\n",
    "rmseR = []\n",
    "mseR=[]\n",
    "maeR=[]\n",
    "r2R=[]\n",
    "cv_rf=[]\n",
    "# model fitting and measuring RMSE\n",
    "for i in range(len(trainX)):\n",
    "  regressor_rf.fit(trainX[i],y_train)\n",
    "    # predict\n",
    "  pred = regressor_rf.predict(testX[i])\n",
    "    # RMSE\n",
    "  rmseR.append(np.sqrt(mean_squared_error(y_test,pred)))\n",
    "  mseR.append(mean_squared_error(y_test,pred))\n",
    "  maeR.append(mean_absolute_error(y_test,pred))\n",
    "  r2R.append(r2_score(y_test,pred))\n",
    "  cv_rf.append(cross_val_score(estimator = regressor_rf, X = trainX[i], y = y_train.ravel(), cv = 10))\n",
    "\n",
    "# visualizing the result    \n",
    "df_RM = pd.DataFrame({'Root Mean Square Error(RMSE-RandomForest)':rmseR},index=['Original','Normalized','Standardized'])\n",
    "df_RME = pd.DataFrame({'Mean Squared Error (MSE-RandomForest)':mseR},index=['Original','Normalized','Standardized'])\n",
    "df_RMA = pd.DataFrame({'Mean Absolute Error (MAE-RandomForest)':maeR},index=['Original','Normalized','Standardized'])\n",
    "df_RM3=pd.DataFrame({'R2 Score-RandomForest':r2R},index=['Original','Normalized','Standardized'])\n",
    "df_RM4 =pd.DataFrame({'Cross Validation-RandomForest':cv_rf},index=['Original','Normalized','Standardized'])\n",
    "result4 = pd.concat([df_RM, df_RME,df_RMA,df_RM3,df_RM4], axis=1, join='inner')\n",
    "result4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c572014",
   "metadata": {
    "id": "6c572014"
   },
   "source": [
    "#### 9.6 Xtreme Gradient Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7825cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "fb7825cf",
    "outputId": "8c8bee9b-976f-4ebd-9bc3-3c544d73c9e4"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "\n",
    "rmseX = []\n",
    "mseX=[]\n",
    "maeX=[]\n",
    "r2X=[]\n",
    "cv_X=[] \n",
    "# model fitting and measuring RMSE\n",
    "for i in range(len(trainX)):\n",
    "  xg_reg.fit(trainX[i],y_train)\n",
    "    # predict\n",
    "  pred = xg_reg.predict(testX[i])\n",
    "    # RMSE\n",
    "  rmseX.append(np.sqrt(mean_squared_error(y_test,pred)))\n",
    "  mseX.append(mean_squared_error(y_test,pred))\n",
    "  maeX.append(mean_absolute_error(y_test,pred))\n",
    "  r2X.append(r2_score(y_test,pred))\n",
    "  cv_X.append(cross_val_score(estimator = regressor_rf, X = trainX[i], y = y_train.ravel(), cv = 10))\n",
    "\n",
    "# visualizing the result    \n",
    "df_X = pd.DataFrame({'Root Mean Square Error(RMSE-xgboost)':rmseX},index=['Original','Normalized','Standardized'])\n",
    "df_X1 = pd.DataFrame({'Mean Squared Error (MSE-xgboost)':mseX},index=['Original','Normalized','Standardized'])\n",
    "df_X2 = pd.DataFrame({'Mean Absolute Error (MAE-xgboost)':maeX},index=['Original','Normalized','Standardized'])\n",
    "df_X3=pd.DataFrame({'R2 Score-xgboost':r2X},index=['Original','Normalized','Standardized'])\n",
    "df_X4=pd.DataFrame({'Cross Validation-xgboost':cv_X},index=['Original','Normalized','Standardized'])\n",
    "result5 = pd.concat([df_X, df_X1,df_X2,df_X3,df_X4], axis=1, join='inner')\n",
    "\n",
    "result5 "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "House Rent Prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
